{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxbiX0EsYUd2"
   },
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43167,
     "status": "ok",
     "timestamp": 1749753376402,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "Fn_I5hDti2__"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from torchvision import models\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtkyIzOLY7EC"
   },
   "source": [
    "Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22186,
     "status": "ok",
     "timestamp": 1749753476805,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "eyegydOvZAY4",
    "outputId": "ad77fe7e-a5d4-4a91-b3b8-5a2340d1d202"
   },
   "outputs": [],
   "source": [
    "dataset_root = kagglehub.dataset_download(\"orvile/brain-cancer-mri-dataset\")\n",
    "data_dir = os.path.join(dataset_root, \"Brain_Cancer raw MRI data\")\n",
    "data_dir = os.path.join(data_dir, \"Brain_Cancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWWCVoTVZWNc"
   },
   "source": [
    "Transformations and Dataset Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1749753484300,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "n3-mPNy4ZZ10"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "class_names = dataset.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9BQoyTjZhVp"
   },
   "source": [
    "Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749753509659,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "fxTY_oK2Zgn1"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaSFeigOzCoW"
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import random\n",
    "# random.seed(42)\n",
    "\n",
    "# class_to_indices = defaultdict(list)\n",
    "# for idx, (_, label) in enumerate(dataset.samples):\n",
    "#     class_to_indices[label].append(idx)\n",
    "\n",
    "# # Sample 100 train and 100 test indices per class\n",
    "# train_indices = []\n",
    "# test_indices = []\n",
    "\n",
    "# for class_id, indices in class_to_indices.items():\n",
    "#     random.shuffle(indices)\n",
    "#     train_indices.extend(indices[:100])\n",
    "#     test_indices.extend(indices[100:200])\n",
    "\n",
    "# # Create subsets using the sampled indices\n",
    "# from torch.utils.data import Subset\n",
    "\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "# test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-93Jv7d3ZoZm"
   },
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749754254637,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "bFYWR-kOZvUi"
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 54 * 54, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ddGM8i3aC4Q"
   },
   "source": [
    "Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1635061,
     "status": "ok",
     "timestamp": 1749755892710,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "s7LSKp2saFaH",
    "outputId": "ef1765d6-2506-4003-db72-190d367ecbea"
   },
   "outputs": [],
   "source": [
    "cnn = SimpleCNN(num_classes=len(class_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "\n",
    "def train_model(model, loader):\n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} - Loss: {running_loss:.4f}\")\n",
    "\n",
    "train_model(cnn, train_loader)\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    print(\"CNN Evaluation:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "evaluate_model(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xagCzUq8ikiA"
   },
   "source": [
    "ViT Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768,
     "referenced_widgets": [
      "863a718654df4617bb6a4ff6042e9756",
      "865cbe3e3f9d454ba918b07f01474f07",
      "51b4cd29594e4d7d9cb7c99b9bac15c9",
      "82e7b0420bb64e89ab3db14f658517cd",
      "15b6b193d2984782a3566de2b34a77a8",
      "cc10d9959cc04c26a61001fa8bbf1e05",
      "9fcaccd0552042ed9a7da35d942514e4",
      "58323d48827a4fa3bdc84be5ac6a1057",
      "8a69782b3acf4e5eb110852364408746",
      "fe3083fccf384a8190b7f1a4d0d887e4",
      "f52754d4f35149849ca03f491156b7a3",
      "de1167f01ba74dfbafb378571390a045",
      "b8ea56aa0ddd44f3bda0d0fc6bda39ec",
      "3a7182d5547643298d5d9b2658bafcd3",
      "ef1bd69be68c40d78599361431336b5b",
      "05c0caac261945cfaa2734485ca3eabf",
      "969edcdade3a4900bd3823b341524fa5",
      "e46912eacd7e494385bf3ea8b1376b39",
      "a97a7e693dfb440b8b10c79cfbc60a45",
      "93333b2357504883a5fbb9c26772bea4",
      "7f7a417982654840ac4cad54fb51471a",
      "941a70eb0ffa4bfd800d2fe9ebbcfb1b",
      "c7811c3ddd97404db382a40a73c8fc91",
      "92f440b0b25a4cb9a55038825687ec63",
      "e968512f408f459890578368849a2785",
      "0d492b268fcb45c09fba0d79dedff3a2",
      "d8b5e943388346d2b4d9094f7a15ac77",
      "70cc1ee24d5d4742806e2008c678fabb",
      "f46815a1a65443a2a8674c3d1f22e749",
      "b05b21b7fc19496fbe062faa1ca0cbc6",
      "41bb261ce81e409ba3e2859fb13d4517",
      "6591a9a5b40f480eb23fc30d2152c9cb",
      "4d0440e22f8f474da6cc48b2fe3df7c0"
     ]
    },
    "executionInfo": {
     "elapsed": 40004,
     "status": "error",
     "timestamp": 1747843548126,
     "user": {
      "displayName": "Peyton Chang",
      "userId": "07092257042067781604"
     },
     "user_tz": 240
    },
    "id": "3c1rVJwZinD8",
    "outputId": "b8a7894b-4293-493e-97a4-f09b779fa4f0"
   },
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=len(class_names)).to(device)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.data = subset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        return {\"pixel_values\": img, \"label\": label}\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "vit_train_dataset = CustomDataset(train_dataset)\n",
    "vit_test_dataset = CustomDataset(test_dataset)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_output\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=vit_model,\n",
    "    args=training_args,\n",
    "    train_dataset=vit_train_dataset,\n",
    "    eval_dataset=vit_test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"ViT Evaluation:\")\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTRgqhoKk26S"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 675627,
     "status": "ok",
     "timestamp": 1749754195445,
     "user": {
      "displayName": "Colin Gnass",
      "userId": "00712648982812520303"
     },
     "user_tz": 240
    },
    "id": "g1JdAegNk6G-",
    "outputId": "147b264c-8788-4385-802a-c9d5c04dd4f7"
   },
   "outputs": [],
   "source": [
    "def extract_features(dataloader):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            output = resnet(imgs).cpu().numpy()\n",
    "            features.extend(output)\n",
    "            labels.extend(lbls.numpy())\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load ResNet once\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# Extract features from train and test sets\n",
    "svm_train_features, svm_train_labels = extract_features(train_loader)\n",
    "svm_test_features, svm_test_labels = extract_features(test_loader)\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(svm_train_features, svm_train_labels)\n",
    "svm_preds = svm.predict(svm_test_features)\n",
    "\n",
    "# Print metrics\n",
    "print(\"SVM Evaluation:\")\n",
    "print(classification_report(svm_test_labels, svm_preds, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
